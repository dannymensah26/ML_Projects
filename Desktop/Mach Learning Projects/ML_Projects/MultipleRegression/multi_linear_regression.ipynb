{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Multiple Linear Regression?\n",
    "\n",
    "MLR, also known as Multiple Linear Regression, models the linear relationship between one dependent variable (response) and two or more independent variables (predictors).\n",
    "\n",
    "\n",
    "IMAGE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict the outcome of the dependent variable based on the values of multiple explanatory variables.\n",
    "\n",
    "Before moving ahead, Let's discuss one important question:\n",
    "\n",
    "#### Why Would One Use a Multiple Regression Over a Simple Linear Regression?\n",
    "\n",
    "A dependent variable is rarely explained by only one variable.\n",
    "\n",
    "Hence, we use Multiple Linear Regression, to explain a dependent variable using more than one independent variable.\n",
    "\n",
    "Note: However, the model assumes that there are no major correlations (multicollinearity) between the independent variables.\n",
    "\n",
    "#### Formula for MLR:\n",
    "\n",
    "The MLR equation for predicting the dependent variable (Y) based on multiple independent variables (X1, X2, …, Xn) is:\n",
    "\n",
    "IMAGE:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "    (Y) = the dependent variable.\n",
    "    β 0 = y-intercept (constant term)\n",
    "    (beta_1, beta_2, …, beta_n) = slope coefficients for each explanatory variable.\n",
    "    (X_1, X_2, …, X_n) = the independent variables.\n",
    "    ϵ = the model’s error term (also known as the residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Importing Dataset\n",
    "\n",
    "In this implementation I am using Diabetes Data of sklearn: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(inputs, target) = load_diabetes(return_X_y = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, test_inputs, train_target, test_target = train_test_split(inputs, target, test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07076875,  0.05068012,  0.01211685, ...,  0.03430886,\n",
       "         0.02736405, -0.0010777 ],\n",
       "       [-0.00914709,  0.05068012, -0.01806189, ...,  0.07120998,\n",
       "         0.00027248,  0.01963284],\n",
       "       [ 0.00538306, -0.04464164,  0.04984027, ..., -0.00259226,\n",
       "         0.01703607, -0.01350402],\n",
       "       ...,\n",
       "       [ 0.03081083, -0.04464164, -0.02021751, ..., -0.03949338,\n",
       "        -0.01090325, -0.0010777 ],\n",
       "       [-0.01277963, -0.04464164, -0.02345095, ..., -0.00259226,\n",
       "        -0.03845972, -0.03835666],\n",
       "       [-0.09269548, -0.04464164,  0.02828403, ..., -0.03949338,\n",
       "        -0.00514219, -0.0010777 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Multiple Linear Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegression:\n",
    "    \n",
    "    # Creating an initializor\n",
    "    def __init__(self):\n",
    "        self.coeff = None\n",
    "        self.intcpt = None\n",
    "        \n",
    "        \n",
    "    # Creating 'fit' Function\n",
    "    def fit(self, train_inputs, train_target):\n",
    "        \n",
    "        # The numpy.insert() function inserts values along the mentioned axis before the given indices.\n",
    "        train_inputs = np.insert(train_inputs, 0, 1, axis = 1) # Syntax : numpy.insert(array, object, values, axis = None) \n",
    "        \n",
    "        # Calculating slope of the line (beta-not):\n",
    "        betas = np.linalg.inv(np.dot(train_inputs.T, train_inputs)).dot(train_inputs.T).dot(train_target)\n",
    "        \n",
    "        self.intcpt = betas[0]\n",
    "        \n",
    "        \n",
    "        # Calculating coefficent of the line(all betas):\n",
    "        self.coeff = betas[1:]\n",
    "        \n",
    "    @property\n",
    "    def coefficients(self):\n",
    "        if self.coeff is not None:\n",
    "            return self.coeff\n",
    "        else:\n",
    "            print(\"Model not fitted yet.\")\n",
    "            return None\n",
    "\n",
    "    @property\n",
    "    def intercept(self):\n",
    "        if self.intcpt is not None:\n",
    "            return self.intcpt\n",
    "        else:\n",
    "            print(\"Model not fitted yet.\")\n",
    "            return None\n",
    "        \n",
    "        \n",
    "    # Creating 'predict' Function\n",
    "    def predict(self, test_inputs):\n",
    "        return np.dot(test_inputs, self.coeff) + self.intcpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = MultipleLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr.fit(train_inputs, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  37.90402135, -241.96436231,  542.42875852,  347.70384391,\n",
       "       -931.48884588,  518.06227698,  163.41998299,  275.31790158,\n",
       "        736.1988589 ,   48.67065743])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.34560453986"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Results: Using sklearn's LinearRegression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_inputs, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  37.90402135, -241.96436231,  542.42875852,  347.70384391,\n",
       "       -931.48884588,  518.06227698,  163.41998299,  275.31790158,\n",
       "        736.1988589 ,   48.67065743])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.34560453985995"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same interecept values.\n",
    "\n",
    "Hence, our model is working fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Regression Metrics: Using R-squared (R²) Score\n",
    "\n",
    "R-squared (R²): Measures the proportion of variance in the dependent variable explained by the independent variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the Regression Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(train_inputs, train_target)\n",
    "plt.plot(train_inputs,lr.predict(train_inputs),color='red')\n",
    "plt.xlabel('input')\n",
    "plt.ylabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_pred = mlr.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR R2 0.4526027629719197\n",
      "MLR R2 0.45260276297191904\n"
     ]
    }
   ],
   "source": [
    "print(\"LR R2\",r2_score(test_target,lr_pred))\n",
    "\n",
    "print(\"MLR R2\",r2_score(test_target,mlr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay, we got same results.\n",
    "\n",
    "We had created an OLS Multiple Linear Regression Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When to Use MLR?\n",
    "\n",
    "MLR is suitable when you want to understand how several independent variables collectively influence a single dependent variable.\n",
    "\n",
    "Example: Predicting house prices based on features like square footage, number of bedrooms, and location.\n",
    "##### Advantages of Multiple Regression:\n",
    "- More Realistic: Real-world phenomena are rarely explained by only one variable. Multiple regression captures the complexity of relationships.\n",
    "- Optimal Predictions: When faced with multiple predictors, MLR combines their information to make a single, optimal prediction for the dependent variable.\n",
    "- Accounting for Confounding: MLR helps control for confounding variables. For example, age and height both influence weight, but MLR considers both simultaneously.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
